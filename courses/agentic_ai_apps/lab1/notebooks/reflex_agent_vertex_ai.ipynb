{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reflex Agent with Vertex AI (Gemini)\n",
        "This notebook demonstrates a simple **reflexion** loop: attempt \u2192 critique \u2192 revise \u2192 repeat until valid.\n",
        "Artifacts are saved to Cloud Storage for grading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json, time, uuid\n",
        "from typing import Any\n",
        "from pydantic import BaseModel, ValidationError\n",
        "from google.cloud import storage, aiplatform\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "PROJECT_ID = os.getenv('PROJECT_ID') or input('Enter PROJECT_ID: ')\n",
        "REGION = os.getenv('REGION','us-central1')\n",
        "BUCKET = os.getenv('BUCKET') or input('Enter BUCKET (no gs://): ')\n",
        "RUN_ID = uuid.uuid4().hex[:8]\n",
        "RUN_PREFIX = f'agent_runs/{RUN_ID}'\n",
        "LATEST_PREFIX = 'agent_runs/latest'\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "model = GenerativeModel('gemini-1.5-pro')\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bucket = storage_client.bucket(BUCKET)\n",
        "print('Using', PROJECT_ID, REGION, BUCKET, RUN_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rubric + schema using Pydantic\n",
        "class Step(BaseModel):\n",
        "    name: str\n",
        "    description: str\n",
        "    inputs: list[str]\n",
        "    outputs: list[str]\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    steps: list[Step]\n",
        "    destination_bq: str\n",
        "\n",
        "SYSTEM_RUBRIC = f'''\n",
        "Return ONLY JSON matching this exact schema:\n",
        "{\n",
        "  \"steps\": [\n",
        "    {\"name\": \"extract\", \"description\": \"...\", \"inputs\": [\"...\"], \"outputs\": [\"...\"]},\n",
        "    {\"name\": \"transform\", \"description\": \"...\", \"inputs\": [\"...\"], \"outputs\": [\"...\"]},\n",
        "    {\"name\": \"load\", \"description\": \"...\", \"inputs\": [\"...\"], \"outputs\": [\"...\"]}\n",
        "  ],\n",
        "  \"destination_bq\": \"{PROJECT_ID}.demo.sales_etl\"\n",
        "}\n",
        "Constraints:\n",
        "- Exactly 3 steps in this order: extract \u2192 transform \u2192 load.\n",
        "- Each step has non-empty fields and at least one input & output.\n",
        "- destination_bq must start with your PROJECT_ID.\n",
        "If you make mistakes, you'll receive a critique. Use it to correct the JSON. Always return pure JSON.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_gcs(path: str, payload: Any):\n",
        "    blob = bucket.blob(path)\n",
        "    if isinstance(payload, (dict, list)):\n",
        "        payload = json.dumps(payload, indent=2)\n",
        "    blob.upload_from_string(str(payload), content_type='application/json')\n",
        "\n",
        "def attempt() -> str:\n",
        "    prompt = (\n",
        "        'Produce the JSON plan per the rubric. Scenario: Read daily CSV from GCS, '\n",
        "        'clean column names and filter out negative price, then load to BigQuery.'\n",
        "    )\n",
        "    return model.generate_content([SYSTEM_RUBRIC, prompt]).text\n",
        "\n",
        "def critique(json_text: str) -> str:\n",
        "    return model.generate_content([\n",
        "        SYSTEM_RUBRIC,\n",
        "        json_text,\n",
        "        'Critique strictly against the rubric. If valid, respond ONLY \"VALID\"; else list minimal issues.'\n",
        "    ]).text\n",
        "\n",
        "def revise(json_text: str, critique_text: str) -> str:\n",
        "    return model.generate_content([\n",
        "        SYSTEM_RUBRIC,\n",
        "        json_text,\n",
        "        critique_text,\n",
        "        'Correct the JSON per the critique. Output ONLY corrected JSON.'\n",
        "    ]).text\n",
        "\n",
        "def validate_plan(json_text: str) -> tuple[bool, str]:\n",
        "    try:\n",
        "        data = json.loads(json_text)\n",
        "        plan = Plan(**data)\n",
        "    except (json.JSONDecodeError, ValidationError) as e:\n",
        "        return False, f'Schema/JSON error: {e}'\n",
        "    names = [s.name.lower() for s in plan.steps]\n",
        "    if names != ['extract','transform','load']:\n",
        "        return False, f'Wrong step order: {names}'\n",
        "    if not plan.destination_bq.startswith(f'{PROJECT_ID}.'):\n",
        "        return False, 'destination_bq must start with PROJECT_ID.'\n",
        "    return True, 'OK'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_ITERS = 4\n",
        "history = []\n",
        "current = attempt()\n",
        "final = {\"status\": \"FAILED\", \"run_id\": RUN_ID}\n",
        "\n",
        "for i in range(1, MAX_ITERS+1):\n",
        "    valid, reason = validate_plan(current)\n",
        "    history.append({\"iter\": i, \"valid\": valid, \"reason\": reason})\n",
        "    write_gcs(f\"agent_runs/{RUN_ID}/iter_{i}.json\", {\"valid\": valid, \"reason\": reason, \"candidate\": current})\n",
        "    if valid:\n",
        "        final = {\"status\": \"SUCCESS\", \"run_id\": RUN_ID, \"iters\": i}\n",
        "        break\n",
        "    fb = critique(current)\n",
        "    write_gcs(f\"agent_runs/{RUN_ID}/iter_{i}_critique.json\", {\"critique\": fb})\n",
        "    current = revise(current, fb)\n",
        "\n",
        "write_gcs(f\"agent_runs/{RUN_ID}/final.json\", {\"history\": history, \"final\": current, \"final_status\": final})\n",
        "write_gcs(\"agent_runs/latest/final.json\", {\"history\": history, \"final\": current, \"final_status\": final})\n",
        "if final[\"status\"] == \"SUCCESS\":\n",
        "    write_gcs(f\"agent_runs/{RUN_ID}/success.json\", final)\n",
        "    write_gcs(\"agent_runs/latest/success.json\", final)\n",
        "final"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}