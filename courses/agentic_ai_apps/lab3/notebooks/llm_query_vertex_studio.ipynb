{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Query via Vertex AI Studio (Gemini)\n",
        "A minimal agent: build a prompt \u2192 call Gemini \u2192 quick self-check \u2192 save artifacts to GCS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json, uuid\n",
        "from google.cloud import storage, aiplatform\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "PROJECT_ID = os.getenv('PROJECT_ID') or input('Project ID: ')\n",
        "REGION = os.getenv('REGION', 'us-central1')\n",
        "BUCKET = os.getenv('BUCKET') or input('Bucket (no gs://): ')\n",
        "RUN_ID = uuid.uuid4().hex[:8]\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "model = GenerativeModel('gemini-1.5-pro')\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bucket = storage_client.bucket(BUCKET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_gcs(path, obj):\n",
        "    blob = bucket.blob(path)\n",
        "    if isinstance(obj, (dict, list)):\n",
        "        obj = json.dumps(obj, indent=2)\n",
        "    blob.upload_from_string(str(obj), content_type='application/json')\n",
        "\n",
        "goal = \"Outline a quickstart to deploy a Flask API on Cloud Run.\"\n",
        "prompt = f\"You are a helpful agent. Provide steps and a checklist. Goal: {goal}\"\n",
        "resp = model.generate_content(prompt)\n",
        "answer = resp.text.strip()\n",
        "\n",
        "check = {\"ok_len\": len(answer.split()) < 160, \"has_step\": \"step\" in answer.lower()}\n",
        "artifacts = {\"goal\": goal, \"answer\": answer, \"check\": check}\n",
        "\n",
        "write_gcs(f'llm_query/{RUN_ID}/result.json', artifacts)\n",
        "if check['ok_len'] and check['has_step']:\n",
        "    write_gcs('llm_query/latest/success.json', {\"status\":\"SUCCESS\",\"run_id\":RUN_ID})\n",
        "artifacts"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}